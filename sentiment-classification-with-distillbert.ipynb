{"cells":[{"metadata":{"id":"PNRnLYn4TW5R"},"cell_type":"markdown","source":["# Setup and imports"]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"fEYBNetWTW5S"},"cell_type":"code","source":["%%capture\n","!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"TeWxspRimJIl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Helper Function"],"metadata":{"id":"_BQN0a6qmSSJ"}},{"cell_type":"code","source":["def tokenize_and_convert_to_tensors(text, labels, max_len=512):\n","    input_ids = []\n","    attention_masks = []\n","\n","    for sentence, label in tqdm(zip(text, labels), total=len(text), desc=\"Tokenizing\"):\n","        encoded_dict = tokenizer.encode_plus(\n","            sentence,\n","            add_special_tokens=True,\n","            max_length=max_len,\n","            padding='max_length',\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","            truncation=True\n","        )\n","\n","        input_ids.append(encoded_dict['input_ids'])\n","        attention_masks.append(encoded_dict['attention_mask'])\n","\n","    input_ids = torch.cat(input_ids, dim=0)\n","    attention_masks = torch.cat(attention_masks, dim=0)\n","    labels = torch.tensor(labels)\n","\n","    return input_ids, attention_masks, labels"],"metadata":{"id":"cqBD3TGZjN_O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Distilbert with finetuning for sentiment classification"],"metadata":{"id":"MaAUlwNHmbgL"}},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from tqdm import tqdm\n","\n","# Load your preprocessed data\n","PATH_OF_TRAINING_DATA = '/content/drive/MyDrive/CS505_final_project/data/IMDB_fine_tune_data.csv'\n","df = pd.read_csv(PATH_OF_TRAINING_DATA)\n","df['sentiment'] = df['sentiment'].apply(lambda x: 1 if x == 'pos' else 0)\n","\n","# Split the data into train and validation sets\n","train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n","\n","# Extract features and labels\n","X_train, y_train = train_df['text'].tolist(), train_df['sentiment'].tolist()\n","X_val, y_val = val_df['text'].tolist(), val_df['sentiment'].tolist()\n","\n","# Tokenizer\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","\n","# Tokenize and convert to PyTorch tensors\n","train_input_ids, train_attention_masks, train_labels = tokenize_and_convert_to_tensors(X_train, y_train)\n","val_input_ids, val_attention_masks, val_labels = tokenize_and_convert_to_tensors(X_val, y_val)\n","\n","# Create DataLoader\n","train_dataset = torch.utils.data.TensorDataset(train_input_ids, train_attention_masks, train_labels)\n","val_dataset = torch.utils.data.TensorDataset(val_input_ids, val_attention_masks, val_labels)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n","\n","# Load pre-trained DistilBERT model for sequence classification\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n","\n","# Set up optimizer and scheduler\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","epochs = 3\n","total_steps = len(train_dataloader) * epochs\n","\n","scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=5e-5, steps_per_epoch=len(train_dataloader), epochs=epochs)\n","\n","# Training loop\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0.0\n","\n","    for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n","        batch = tuple(t.to(device) for t in batch)\n","        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n","        optimizer.zero_grad()\n","        outputs = model(**inputs)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","\n","    avg_train_loss = total_loss / len(train_dataloader)\n","    print(f\"Average training loss: {avg_train_loss}\")\n","\n","    # Validation\n","    model.eval()\n","    val_preds = []\n","    val_true = []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(val_dataloader, desc=f\"Validation\"):\n","            batch = tuple(t.to(device) for t in batch)\n","            inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n","            outputs = model(**inputs)\n","            logits = outputs.logits\n","            preds = torch.argmax(logits, dim=1).cpu().numpy()\n","            labels = batch[2].cpu().numpy()\n","            val_preds.extend(preds)\n","            val_true.extend(labels)\n","\n","    val_accuracy = accuracy_score(val_true, val_preds)\n","    print(f\"Validation Accuracy: {val_accuracy}\")\n","\n","# Save the model if needed\n","model.save_pretrained('fine_tuned_distilbert_imdb')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381,"referenced_widgets":["471275aad2eb44d8b3a2b8f36f6b7389","30a7c4fd0a394a559889f0f9eed0826b","d5ee55b7030f493fbdda696277fa0221","a7bd0d2cd0c04cf69ad67b4a6e906da2","65527a328e11439583efe313cccae2a8","c91f5cfad2f743b6aafc6714ab97ea91","6a03723ac026413fbbe3133547ce29ba","126500a3d998470daeb7518f404fb921","04b23a4cdbfc4c918001bb9097fc0bd1","40c669981d6943d893dc8e673cc0faac","7465525122924814889a138eba22cbdc"]},"id":"ts5JGHSN2f_I","executionInfo":{"status":"ok","timestamp":1702100085403,"user_tz":300,"elapsed":3500200,"user":{"displayName":"Haoran Hu","userId":"05657804770352929226"}},"outputId":"51f0d4d1-c6f1-4fc6-e98b-0959fc04bf5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Tokenizing: 100%|██████████| 22500/22500 [02:23<00:00, 156.35it/s]\n","Tokenizing: 100%|██████████| 2500/2500 [00:16<00:00, 149.41it/s]\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"471275aad2eb44d8b3a2b8f36f6b7389"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","Epoch 1/3: 100%|██████████| 2813/2813 [17:48<00:00,  2.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Average training loss: 0.3185298505026968\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 313/313 [00:40<00:00,  7.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.9028\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/3: 100%|██████████| 2813/2813 [17:48<00:00,  2.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Average training loss: 0.17377062002031368\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 313/313 [00:41<00:00,  7.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.9244\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/3: 100%|██████████| 2813/2813 [17:48<00:00,  2.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Average training loss: 0.04199532235924494\n"]},{"output_type":"stream","name":"stderr","text":["Validation: 100%|██████████| 313/313 [00:40<00:00,  7.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.9252\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n","from torch.utils.data import DataLoader, TensorDataset\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score"],"metadata":{"id":"F4WSxjlAHarI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PATH_OF_AMAZON_DATA = '/content/drive/MyDrive/CS505_final_project/data/Amazon_review_testing_data.csv'  # Replace with the actual path\n","amazon_df = pd.read_csv(PATH_OF_AMAZON_DATA)"],"metadata":{"id":"_Mv4HiHHGKZG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Select the first and third columns\n","amazon_df = amazon_df.iloc[:, [0, 2]]\n","\n","# Rename the columns\n","amazon_df.columns = ['sentiment', 'review']\n","\n","# Replace values in the 'sentiment' column\n","amazon_df['sentiment'] = amazon_df['sentiment'].replace({1: 0, 2: 1})\n","\n","# Display the resulting DataFrame\n","print(amazon_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fScMCKVyGSN5","executionInfo":{"status":"ok","timestamp":1702100622632,"user_tz":300,"elapsed":16,"user":{"displayName":"Haoran Hu","userId":"05657804770352929226"}},"outputId":"ee6f6b03-cc90-4a00-f0ef-19adaa2a81a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   sentiment                                             review\n","0          1  Despite the fact that I have only played a sma...\n","1          0  I bought this charger in Jul 2003 and it worke...\n","2          1  Check out Maha Energy's website. Their Powerex...\n","3          1  Reviewed quite a bit of the combo players and ...\n","4          0  I also began having the incorrect disc problem...\n"]}]},{"cell_type":"code","source":["# Extract features and labels\n","X_test, y_test = amazon_df['review'].tolist(), amazon_df['sentiment'].tolist()\n","\n","# Tokenizer\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","\n","# Tokenize and convert to PyTorch tensors\n","test_input_ids, test_attention_masks, test_labels = tokenize_and_convert_to_tensors(X_test, y_test)\n","\n","# Create DataLoader\n","test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n","test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n","\n","# Load the fine-tuned model\n","# model = DistilBertForSequenceClassification.from_pretrained('fine_tuned_distilbert_imdb')  # Use the path where you saved the fine-tuned model\n","# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# model.to(device)\n","\n","# Prediction loop\n","model.eval()\n","test_preds = []\n","test_true = []\n","\n","with torch.no_grad():\n","    for batch in tqdm(test_dataloader, desc=\"Testing\"):\n","        batch = tuple(t.to(device) for t in batch)\n","        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","        preds = torch.argmax(logits, dim=1).cpu().numpy()\n","        labels = batch[2].cpu().numpy()\n","        test_preds.extend(preds)\n","        test_true.extend(labels)\n","\n","# Calculate accuracy on the test set\n","test_accuracy = accuracy_score(test_true, test_preds)\n","print(f\"Test Accuracy: {test_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eGmLTn3JF5Cb","executionInfo":{"status":"ok","timestamp":1702108234762,"user_tz":300,"elapsed":7379952,"user":{"displayName":"Haoran Hu","userId":"05657804770352929226"}},"outputId":"d94d5c2f-fdb6-4db8-82fc-9d9f2a96e89b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Tokenizing: 100%|██████████| 399999/399999 [15:11<00:00, 438.68it/s]\n","Testing: 100%|██████████| 50000/50000 [1:47:43<00:00,  7.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Test Accuracy: 0.8827947069867674\n"]}]},{"cell_type":"markdown","source":["# Distilbert without finetuning for sentiment classification"],"metadata":{"id":"r5e6MdZPmqMs"}},{"cell_type":"code","source":["import torch\n","from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n","from sklearn.metrics import accuracy_score\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","\n","# Load your dataset\n","PATH_OF_AMAZON_DATA = '/content/drive/MyDrive/CS505_final_project/data/Amazon_review_testing_data.csv'  # Replace with the actual path\n","og_amazon_df = pd.read_csv(PATH_OF_AMAZON_DATA)\n","\n","# Select the first and third columns\n","og_amazon_df = og_amazon_df.iloc[:, [0, 2]]\n","\n","# Rename the columns\n","og_amazon_df.columns = ['sentiment', 'review']\n","\n","# Replace values in the 'sentiment' column\n","og_amazon_df['sentiment'] = og_amazon_df['sentiment'].replace({1: 0, 2: 1})\n","\n","# Split the dataset into training and testing sets\n","origin_train_df, origin_test_df = train_test_split(og_amazon_df, test_size=0.2, random_state=42)\n","\n","class OGAmazonDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_len):\n","        self.texts = texts\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = str(self.texts[idx])\n","        label = int(self.labels[idx])\n","        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_len, return_tensors='pt')\n","        return {'input_ids': encoding['input_ids'].squeeze(),\n","                'attention_mask': encoding['attention_mask'].squeeze(),\n","                'label': torch.tensor(label, dtype=torch.long)}\n","\n","# Load the pre-trained DistilBERT model and tokenizer\n","# Load the pre-trained DistilBERT model and tokenizer\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","origin_amazon_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)  # 2 labels for binary classification\n","origin_amazon_model.to(device)\n","# Define the dataset and dataloaders\n","max_len = 200  # You can adjust this based on your needs\n","test_dataset = OGAmazonDataset(origin_test_df['review'].values, origin_test_df['sentiment'].values, tokenizer, max_len)\n","\n","test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n","\n","# Evaluation\n","origin_amazon_model.eval()\n","all_predictions = []\n","all_labels = []\n","\n","for batch in test_dataloader:\n","    input_ids = batch['input_ids'].to(device)\n","    attention_mask = batch['attention_mask'].to(device)\n","    labels = batch['label'].to(device)\n","\n","    with torch.no_grad():\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","        predictions = torch.argmax(logits, dim=1).cpu().numpy()\n","\n","    all_predictions.extend(predictions)\n","    all_labels.extend(labels.cpu().numpy())\n","\n","accuracy = accuracy_score(all_labels, all_predictions)\n","print(f'Accuracy: {accuracy * 100:.2f}%')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aZ-VtsSIjt90","outputId":"f08fef76-a16d-4e7e-ff93-d312d0f070f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 88.20%\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["PNRnLYn4TW5R","pVDNTzDPTW5V","rotrJGnAWoyU"]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"471275aad2eb44d8b3a2b8f36f6b7389":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30a7c4fd0a394a559889f0f9eed0826b","IPY_MODEL_d5ee55b7030f493fbdda696277fa0221","IPY_MODEL_a7bd0d2cd0c04cf69ad67b4a6e906da2"],"layout":"IPY_MODEL_65527a328e11439583efe313cccae2a8"}},"30a7c4fd0a394a559889f0f9eed0826b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c91f5cfad2f743b6aafc6714ab97ea91","placeholder":"​","style":"IPY_MODEL_6a03723ac026413fbbe3133547ce29ba","value":"model.safetensors: 100%"}},"d5ee55b7030f493fbdda696277fa0221":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_126500a3d998470daeb7518f404fb921","max":267954768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_04b23a4cdbfc4c918001bb9097fc0bd1","value":267954768}},"a7bd0d2cd0c04cf69ad67b4a6e906da2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40c669981d6943d893dc8e673cc0faac","placeholder":"​","style":"IPY_MODEL_7465525122924814889a138eba22cbdc","value":" 268M/268M [00:01&lt;00:00, 223MB/s]"}},"65527a328e11439583efe313cccae2a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c91f5cfad2f743b6aafc6714ab97ea91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a03723ac026413fbbe3133547ce29ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"126500a3d998470daeb7518f404fb921":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04b23a4cdbfc4c918001bb9097fc0bd1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"40c669981d6943d893dc8e673cc0faac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7465525122924814889a138eba22cbdc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}